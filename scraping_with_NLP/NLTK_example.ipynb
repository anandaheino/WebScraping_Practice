{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros passos com Natural Language Toolkit \n",
    "\n",
    "Referência: https://towardsdatascience.com/text-preprocessing-with-nltk-9de5de891658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /home/anandaheino/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fellow-Citizens of the Senate and of the House of Representatives:\\n\\nAmong the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Usando um dataset disponibilizado pelo nltk\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "\n",
    "corpus = inaugural.raw('1789-Washington.txt')\n",
    "corpus[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de frases: 23\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sentences = nltk.sent_tokenize(corpus)\n",
    "print('número de frases:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de palavras: 1537\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(corpus)\n",
    "print('número de palavras:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de palavras únicas: 626\n"
     ]
    }
   ],
   "source": [
    "print('número de palavras únicas:', len(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em ingles, o numero de stopwords é: 179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print('Em ingles, o numero de stopwords é:',len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(w for w in words if w not in stop_words)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "* NLTK provides many inbuilt stemmers such as: \n",
    "  * Porter Stemmer * also used  <---\n",
    "  * Snowball Stemmer * better  <---\n",
    "  * Lancaster Stemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Porter stemmed words: ***\n",
      "  ['grow', 'leav', 'fairli', 'cat', 'troubl', 'misunderstand', 'friendship', 'easili', 'ration', 'relat']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer \n",
    "\n",
    "example_words = [\"grows\",\"leaves\",\"fairly\",\"cats\",\"trouble\",\n",
    "                 \"misunderstanding\",\"friendships\",\"easily\", \n",
    "                 \"rational\", \"relational\"]\n",
    "\n",
    "#Create instances of both stemmers, and stem the words using them.\n",
    "stemmer_ps = PorterStemmer() \n",
    "\n",
    "#an instance of Porter Stemmer\n",
    "\n",
    "stemmed_words_ps = [stemmer_ps.stem(word) for word in example_words]\n",
    "print(\"*** Porter stemmed words: ***\\n \", stemmed_words_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Snowball stemmed words: ***\n",
      "  ['grow', 'leav', 'fair', 'cat', 'troubl', 'misunderstand', 'friendship', 'easili', 'ration', 'relat']\n"
     ]
    }
   ],
   "source": [
    "stemmer_ss = SnowballStemmer(\"english\")   \n",
    "\n",
    "#an instance of Snowball Stemmer\n",
    "stemmed_words_ss = [stemmer_ss.stem(word) for word in example_words]\n",
    "print(\"*** Snowball stemmed words: ***\\n \", stemmed_words_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "* Lemmatization is the algorithmic process of finding the lemma of a word depending on their meaning. \n",
    "* Usually refers to the morphological analysis of words removing inflectional endings. \n",
    "* It helps in returning the base or dictionary form of a word, which is known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/anandaheino/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** The lemmatized words: ***\n",
      "  ['grows', 'leaf', 'fairly', 'cat', 'trouble', 'misunderstanding', 'friendship', 'easily', 'rational', 'relational']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()  \n",
    "\n",
    "# instanciating Word Net Lemmatizer\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in example_words] \n",
    "print(\"*** The lemmatized words: ***\\n \", lemmatized_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** The lemmatized words using a POS tag: ***\n",
      "  ['grow', 'leave', 'fairly', 'cat', 'trouble', 'misunderstand', 'friendships', 'easily', 'rational', 'relational']\n"
     ]
    }
   ],
   "source": [
    "#prints the lemmatized words\n",
    "lemmatized_words_pos = [lemmatizer.lemmatize(word, pos = \"v\") for word in example_words]\n",
    "print(\"*** The lemmatized words using a POS tag: ***\\n \", lemmatized_words_pos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are Stemming and Lemmatization Different?\n",
    "1. Stemming reduces word-forms to stems in order to reduce size, whereas lemmatization reduces the word-forms to linguistically valid lemmas.\n",
    "2. Lemmatization is usually more sophisticated and requires some sort of lexica. Stemming, on the other hand, can be achieved with simple rule-based approaches.\n",
    "3. A stemmer operates on a single word without knowledge of the context, and cannot discriminate between words which have similar/different meanings depending on part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
