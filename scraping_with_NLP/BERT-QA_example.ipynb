{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP | Modelo de Question Answering baseado no BERT base (estudo de caso em português)\n",
    "* buscar uma resposta em um texto (modelo de Question Answering, QA)\n",
    "\n",
    "Referências: \n",
    "* https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78\n",
    "* https://towardsdatascience.com/question-and-answering-with-bert-6ef89a78dac#_=_\n",
    "\n",
    "## 1. HuggingFace’s Transformers\n",
    "\n",
    "First things first — modern NLP is dominated by these incredible models called transformers.\n",
    "\n",
    "the real-world implementation of transformers is carried out almost exclusively using a library called `transformers` built by an incredible collection of people that refer to themselves as HuggingFace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando TRANSFORMERS and TENSORFLOW\n",
    "    # pip install transformes\n",
    "    # pip install tensorflow ---> 454.3 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Pytorch:',torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importamos o `transformers`;\n",
    "* inicializando o modelo escolhido: https://huggingface.co/neuralmind/bert-base-portuguese-cased\n",
    "* inicializando o tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anandaheino/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForQuestionAnswering, AutoModelForMaskedLM, pipeline \n",
    "# from transformers import AutoModel *or BertModel, for BERT without pretraining heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que inicializamos o modelo, o tokenizer precisamos inicial o `pipeline` para começar a fazer as perguntas e obter as respostas:\n",
    "\n",
    "* Entrada:\n",
    "  * context\n",
    "  * question\n",
    "* Saída:\n",
    "  * Answer\n",
    "  * score\n",
    "  * start\n",
    "  * end\n",
    "  \n",
    "## É simples, mas é exatamente o que precisamos para começar a fazer um modelo Q&A!\n",
    "* Podemos ver que a 'answer' não está exatamente correta pois foram inseridas palavras a mais. \n",
    "* para isso será necessário dar um FINE-TUNE no modelo, treinando-o com os nossos exemplos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.00029093303601257503,\n",
       " 'start': 144,\n",
       " 'end': 199,\n",
       " 'answer': 'Cor do hilo: Marrom clara Exigência em fertilidade: Sul'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo: \n",
    "\n",
    "context = \"Características: Maturação relativa: Sul: 6.6 / Cerrado: 7.5 Tipo de crescimento: Semideterminado Cor da flor: Branca Cor da Pubescência: Cinza Cor do hilo: Marrom clara Exigência em fertilidade: Sul: Média-Alta / Cerrado: Alta Acamamento: Mod. Resistente PMG*: Sul 180 g / Cerrado: 145 a 160 g\"\n",
    "           \n",
    "nlp({'question': 'Qual é a cor do hilo?', 'context': context})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com uma semente de cada empresa: \n",
    "* `html2text` de uma semente da TMG\n",
    "\n",
    "https://www.tmg.agr.br/ptbr/cultivar/tmg-2375-ipro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup \n",
    "from html2text import html2text\n",
    "\n",
    "link = 'https://www.tmg.agr.br/ptbr/cultivar/tmg-2375-ipro'\n",
    "html = urlopen(link)\n",
    "scrap = BeautifulSoup(html, 'html.parser')\n",
    "pagina = html2text(scrap.prettify()).lower()\n",
    "context = pagina[955:-4246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'answers': \n",
    " {'answer_start': [answer_start],\n",
    "  'text': answer_text},\n",
    " 'context': context,\n",
    " 'id': ID,\n",
    " 'question': question,\n",
    " 'title': pagina}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a adc de tokens seguindo o tutorial abaixo:\n",
    "https://github.com/piegu/language-models/blob/master/nlp_how_to_add_a_domain_specific_vocabulary_new_tokens_to_a_subword_tokenizer_already_trained_like_BERT_WordPiece.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pontos', 'fortes', ':', 'cer', '##rado', ':', 'excelente', 'capacidade', 'de', 'enga', '##l', '##hamento', 'e', 'crescimento', ',', 'com', 'ap', '##tidão', 'para', 'abertura', 'de', 'plantio', '.', 'sul', ':', 'ampla', 'adaptação', ',', 'alto', 'potencial', 'produ', '##tivo', ',', 'excelente', 'opção', 'para', 'antecip', '##ação', 'de', 'plantio', 'e', 'permite', 'milho', 'segunda', 'sa', '##fra', '.', '*', '*', '*', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'caracter', '##istic', '##as', '.', 's', '##v', '##g', ')', '#', '#', 'características', ':', 'mat', '##uração', 'relativa', ':', '*', '*', 'sul', ':', '6', '.', '6', '/', 'cer', '##rado', ':', '7', '.', '5', '*', '*', 'tipo', 'de', 'crescimento', ':', '*', '*', 'semi', '##de', '##termin', '##ado', '*', '*', 'cor', 'da', 'flor', ':', '*', '*', 'branca', '*', '*', 'cor', 'da', 'pu', '##bes', '##cência', ':', '*', '*', 'cinza', '*', '*', 'cor', 'do', 'hi', '##lo', ':', '*', '*', 'marrom', 'clara', '*', '*', 'exigência', 'em', 'fertilidade', ':', '*', '*', 'sul', ':', 'média', '-', 'alta', '/', 'cer', '##rado', ':', 'alta', '*', '*', 'aca', '##ma', '##mento', ':', '*', '*', 'mod', '.', 'resistente', '*', '*', 'p', '##m', '##g', '*', ':', '*', '*', 'sul', '180', 'g', '/', 'cer', '##rado', ':', '145', 'a', '160', 'g', '*', '*', '*', 'o', 'p', '##m', '##g', 'poderá', 'variar', 'dependendo', 'do', 'ambiente', 'em', 'que', 'a', 'cultiv', '##ar', 'for', 'explora', '##da', '.', 'amostras', 'coleta', '##das', 'na', 'sa', '##fra', '18', '/', '19', '.', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'rea', '##co', '##es', '##do', '##en', '##cas', '.', 's', '##v', '##g', ')', '#', '#', 'reação', 'a', 'nem', '##ato', '##ides', 'e', 'doenças', ':', 'cancro', 'da', 'haste', '_', '(', 'dia', '##port', '##he', 'as', '##pal', '##ath', '##i', ')', '_', ':', '*', '*', 'resistente', '*', '*', 'po', '##d', '##rid', '##ão', 'radic', '##ular', 'de', 'fi', '##tó', '##ft', '##ora', '_', '(', 'p', '.', 'soja', '##e', ')', '_', ':', '*', '*', 'susce', '##tível', '*', '*', 'p', '##ús', '##tu', '##la', 'ba', '##cter', '##iana', '_', '(', 'x', '.', 'ax', '##ono', '##po', '##dis', ')', '_', ':', '*', '*', 'resistente', '*', '*', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'indica', '##ca', '##op', '##lan', '##tio', '.', 's', '##v', '##g', ')', '#', '#']\n"
     ]
    }
   ],
   "source": [
    "# tokenization of the text\n",
    "tokens = tokenizer.tokenize(context)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podemos ver que as palavras abaixo não foram reconhecidas na tokenização do texto do site: \n",
    "`cerrado`\n",
    "`engalhamento`\n",
    "`aptidão`\n",
    "`produtivo`\n",
    "`antecipação`\n",
    "`safra`\n",
    "`maturação`\n",
    "`Semideterminado`\n",
    "`Pubescência`\n",
    "`hilo`\n",
    "`Acamamento`\n",
    "`PMG`\n",
    "`cultivar`\n",
    "`nematoides`\n",
    "`Diaporthe`\n",
    "`aspalathi`\n",
    "`Podridão`\n",
    "`radicular`\n",
    "`fitóftora`\n",
    "`Suscetível`\n",
    "`Pústula`\n",
    "`bacteriana`\n",
    "`axonopodis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ['cerrado','engalhamento','aptidão','produtivo','antecipação','safra','maturação','Semideterminado', 'Pubescência', 'hilo', 'Acamamento', 'PMG', 'cultivar', 'nematoides', 'Diaporthe', 'aspalathi', 'Podridão','podridão', 'radicular', 'fitóftora', 'Suscetível','suscetível', 'Pústula', 'bacteriana', 'axonopodis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29819\n"
     ]
    }
   ],
   "source": [
    "added_tokens = tokenizer.add_tokens(new)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29819, 768)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize the embeddings matrix of the model \n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the words belong to the tokenizer vocabulary\n",
    "vocab = [tok for tok,index in tokenizer.get_vocab().items()]\n",
    "\"aptidão\" in vocab, \"Semideterminado\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pontos', 'fortes', ':', 'cerrado', ':', 'excelente', 'capacidade', 'de', 'engalhamento', 'e', 'crescimento', ',', 'com', 'aptidão', 'para', 'abertura', 'de', 'plantio', '.', 'sul', ':', 'ampla', 'adaptação', ',', 'alto', 'potencial', 'produtivo', ',', 'excelente', 'opção', 'para', 'antecipação', 'de', 'plantio', 'e', 'permite', 'milho', 'segunda', 'safra', '.', '*', '*', '*', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'caracter', '##istic', '##as', '.', 's', '##v', '##g', ')', '#', '#', 'características', ':', 'maturação', 'relativa', ':', '*', '*', 'sul', ':', '6', '.', '6', '/', 'cerrado', ':', '7', '.', '5', '*', '*', 'tipo', 'de', 'crescimento', ':', '*', '*', 'semi', '##de', '##termin', '##ado', '*', '*', 'cor', 'da', 'flor', ':', '*', '*', 'branca', '*', '*', 'cor', 'da', 'pu', '##bes', '##cência', ':', '*', '*', 'cinza', '*', '*', 'cor', 'do', 'hilo', ':', '*', '*', 'marrom', 'clara', '*', '*', 'exigência', 'em', 'fertilidade', ':', '*', '*', 'sul', ':', 'média', '-', 'alta', '/', 'cerrado', ':', 'alta', '*', '*', 'aca', '##ma', '##mento', ':', '*', '*', 'mod', '.', 'resistente', '*', '*', 'p', '##m', '##g', '*', ':', '*', '*', 'sul', '180', 'g', '/', 'cerrado', ':', '145', 'a', '160', 'g', '*', '*', '*', 'o', 'p', '##m', '##g', 'poderá', 'variar', 'dependendo', 'do', 'ambiente', 'em', 'que', 'a', 'cultivar', 'for', 'explora', '##da', '.', 'amostras', 'coleta', '##das', 'na', 'safra', '18', '/', '19', '.', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'rea', '##co', '##es', '##do', '##en', '##cas', '.', 's', '##v', '##g', ')', '#', '#', 'reação', 'a', 'nematoides', 'e', 'doenças', ':', 'cancro', 'da', 'haste', '_', '(', 'dia', '##port', '##he', 'aspalathi', ')', '_', ':', '*', '*', 'resistente', '*', '*', 'podridão', 'radicular', 'de', 'fitóftora', '_', '(', 'p', '.', 'soja', '##e', ')', '_', ':', '*', '*', 'suscetível', '*', '*', 'p', '##ús', '##tu', '##la', 'bacteriana', '_', '(', 'x', '.', 'axonopodis', ')', '_', ':', '*', '*', 'resistente', '*', '*', '!', '[', ']', '(', 'http', '##s', ':', '/', '/', 'w', '##ww', '.', 't', '##m', '##g', '.', 'ag', '##r', '.', 'b', '##r', '/', 'imag', '##es', '/', 'icon', '##s', '/', 'indica', '##ca', '##op', '##lan', '##tio', '.', 's', '##v', '##g', ')', '#', '#']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_exBERT = tokenizer\n",
    "\n",
    "# tokenization of the text\n",
    "tokens = tokenizer_exBERT.tokenize(context)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
